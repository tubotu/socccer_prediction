{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28186\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "split_num = 10\n",
    "\n",
    "\n",
    "# data input \n",
    "path = 'trainrat_new.txt'\n",
    "data = pd.read_csv(path,sep=' ')\n",
    "print(len(data))\n",
    "\n",
    "# Data extraction,Win\n",
    "win_data = data[data.label == \"W\"]\n",
    "win_data = win_data.assign(W=1,D=0,L=0) \n",
    "win_data = win_data.drop(\"label\",axis=1)\n",
    "win_data = win_data.sample(n=len(win_data))# random sort\n",
    "\n",
    "# Data extraction,Draw\n",
    "draw_data = data[data.label == \"D\"]\n",
    "draw_data = draw_data.assign(W=0,D=1,L=0)\n",
    "draw_data = draw_data.drop(\"label\",axis=1)\n",
    "draw_data = draw_data.sample(n=len(draw_data))# random sort\n",
    "\n",
    "# Data extraction,Lose\n",
    "lose_data = data[data.label == \"L\"]\n",
    "lose_data = lose_data.assign(W=0,D=0,L=1) \n",
    "lose_data = lose_data.drop(\"label\",axis=1)\n",
    "lose_data = lose_data.sample(n=len(lose_data))# random sort\n",
    "\n",
    "# Group data together,use for normal k-fold\n",
    "all_data = pd.concat([win_data, draw_data, lose_data])\n",
    "all_data = all_data.sample(n=len(all_data))# random sort\n",
    "#yAll = xAll[[\"W\",\"D\",\"L\"]]\n",
    "\n",
    "# Data drop\n",
    "#xWin = xWin.drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "#xDraw = xDraw.drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "#xLose = xLose.drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "#xAll = xAll.drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "\n",
    "# Data separate and making dataset\n",
    "win_data_separate = []\n",
    "draw_data_separate = []\n",
    "lose_data_separate = []\n",
    "all_data_separate = []\n",
    "wdl_separate = []\n",
    "for i in range(split_num):\n",
    "    win_data_separate.append(win_data[i::split_num])\n",
    "    draw_data_separate.append(draw_data[i::split_num])\n",
    "    lose_data_separate.append(lose_data[i::split_num])\n",
    "    all_data_separate.append(all_data[i::split_num])\n",
    "    # merge for stratified sampling\n",
    "    wdl_separate.append(pd.concat([win_data_separate[i],draw_data_separate[i],lose_data_separate[i]]))\n",
    "    # assign a number to make final input data\n",
    "    wdl_separate[i] = wdl_separate[i].assign(separate_num=i)\n",
    "    all_data_separate[i] = all_data_separate[i].assign(separate_num=i)\n",
    "\n",
    "# integrate everything once\n",
    "wdl_separate_merge = wdl_separate[0]\n",
    "all_data_separate_merge = all_data_separate[0]\n",
    "for i in range(1,split_num):\n",
    "    wdl_separate_merge = wdl_separate_merge.append(wdl_separate[i])\n",
    "    all_data_separate_merge = all_data_separate_merge.append(all_data_separate[i])\n",
    "\n",
    "#print(len(wdl_separate_merge))\n",
    "#print(len(all_data_separate_merge))\n",
    "    \n",
    "    \n",
    "# make final input data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "xAll_train = []\n",
    "yAll_train = []\n",
    "xAll_val = []\n",
    "yAll_val = []\n",
    "for i in range(split_num):\n",
    "    x_train.append(wdl_separate_merge[wdl_separate_merge['separate_num'] != i])\n",
    "    x_val.append(wdl_separate_merge[wdl_separate_merge['separate_num'] == i])\n",
    "    xAll_train.append(all_data_separate_merge[all_data_separate_merge['separate_num'] != i])\n",
    "    xAll_val.append(all_data_separate_merge[all_data_separate_merge['separate_num'] == i])\n",
    "for i in range(split_num):\n",
    "    # delete separate_num\n",
    "    x_train[i] = x_train[i].drop(['separate_num'],axis=1)\n",
    "    x_val[i] = x_val[i].drop(['separate_num'],axis=1)\n",
    "    xAll_train[i] = xAll_train[i].drop(['separate_num'],axis=1)\n",
    "    xAll_val[i] = xAll_val[i].drop(['separate_num'],axis=1)\n",
    "    # random sort\n",
    "    x_train[i] = x_train[i].sample(n=len(x_train[i]))\n",
    "    x_val[i] = x_val[i].sample(n=len(x_val[i]))\n",
    "    xAll_train[i] = xAll_train[i].sample(n=len(xAll_train[i]))\n",
    "    xAll_val[i] = xAll_val[i].sample(n=len(xAll_val[i]))\n",
    "    \n",
    "    # separate x and y\n",
    "    y_train.append(x_train[i][[\"W\",\"D\",\"L\"]])\n",
    "    y_val.append(x_val[i][[\"W\",\"D\",\"L\"]])\n",
    "    yAll_train.append(xAll_train[i][[\"W\",\"D\",\"L\"]])\n",
    "    yAll_val.append(xAll_val[i][[\"W\",\"D\",\"L\"]])\n",
    "    x_train[i] = x_train[i].drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "    x_val[i] = x_val[i].drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "    xAll_train[i] = xAll_train[i].drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "    xAll_val[i] = xAll_val[i].drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "    \n",
    "    #translate pandas to numpy\n",
    "    x_train[i] = x_train[i].values.astype('float32') \n",
    "    x_val[i] = x_val[i].values.astype('float32') \n",
    "    y_train[i] = y_train[i].values\n",
    "    y_val[i] = y_val[i].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPS(y_true, y_pred):\n",
    "    output = 0.\n",
    "    data_num = len(y_true)\n",
    "    for i in range(data_num):\n",
    "        times = len(y_true[i]) - 1 \n",
    "        cumulative_sum = 0.\n",
    "        score = 0.\n",
    "        for time in range(times):\n",
    "            cumulative_sum += y_true[i,time] - y_pred[i,time]\n",
    "            score += cumulative_sum ** 2\n",
    "        score /= times\n",
    "        output += score\n",
    "    \n",
    "    output /= data_num\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tubotu/.local/lib/python3.6/site-packages/chainer/backends/cuda.py:143: UserWarning: cuDNN is not enabled.\n",
      "Please reinstall CuPy after you install cudnn\n",
      "(see https://docs-cupy.chainer.org/en/stable/install.html#install-cudnn).\n",
      "  'cuDNN is not enabled.\\n'\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import Sequential\n",
    "\n",
    "# craete model\n",
    "# net としてインスタンス化\n",
    "n_input = 8\n",
    "n_hidden = 10\n",
    "n_output = 3\n",
    "\n",
    "# create 10 model for 10-fold-crossvalidation?\n",
    "optimizer = []\n",
    "net = []\n",
    "\n",
    "for i in range(10):\n",
    "    net.append(Sequential(\n",
    "        L.Linear(n_input, n_hidden), F.relu,\n",
    "        L.Linear(n_hidden, n_hidden), F.relu,\n",
    "        L.Linear(n_hidden, n_output), F.softmax)\n",
    "    )\n",
    "    optimizer.append(chainer.optimizers.SGD(lr=0.01))\n",
    "    optimizer[i].setup(net[i])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 1586, loss (train): 0.2191, loss (valid): 0.2122\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2130, loss (valid): 0.2089\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2116, loss (valid): 0.2081\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2111, loss (valid): 0.2078\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2108, loss (valid): 0.2075\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2106, loss (valid): 0.2073\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2104, loss (valid): 0.2072\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2103, loss (valid): 0.2072\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2102, loss (valid): 0.2071\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2101, loss (valid): 0.2070\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2100, loss (valid): 0.2070\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2100, loss (valid): 0.2069\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2099, loss (valid): 0.2069\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2099, loss (valid): 0.2068\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2098, loss (valid): 0.2068\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2098, loss (valid): 0.2067\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2097, loss (valid): 0.2067\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2097, loss (valid): 0.2067\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2097, loss (valid): 0.2066\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2096, loss (valid): 0.2066\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2096, loss (valid): 0.2066\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2096, loss (valid): 0.2065\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2096, loss (valid): 0.2065\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2095, loss (valid): 0.2065\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2095, loss (valid): 0.2064\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2095, loss (valid): 0.2064\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2095, loss (valid): 0.2064\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2095, loss (valid): 0.2064\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2094, loss (valid): 0.2064\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2094, loss (valid): 0.2063\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2322, loss (valid): 0.2197\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2173, loss (valid): 0.2163\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2149, loss (valid): 0.2152\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2138, loss (valid): 0.2145\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2130, loss (valid): 0.2139\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2124, loss (valid): 0.2134\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2119, loss (valid): 0.2130\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2115, loss (valid): 0.2127\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2112, loss (valid): 0.2124\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2109, loss (valid): 0.2122\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2106, loss (valid): 0.2120\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2104, loss (valid): 0.2118\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2102, loss (valid): 0.2116\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2101, loss (valid): 0.2115\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2099, loss (valid): 0.2114\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2098, loss (valid): 0.2113\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2097, loss (valid): 0.2112\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2096, loss (valid): 0.2111\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2096, loss (valid): 0.2111\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2095, loss (valid): 0.2110\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2094, loss (valid): 0.2110\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2094, loss (valid): 0.2109\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2093, loss (valid): 0.2109\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2093, loss (valid): 0.2108\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2092, loss (valid): 0.2108\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2092, loss (valid): 0.2108\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2092, loss (valid): 0.2107\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2091, loss (valid): 0.2107\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2091, loss (valid): 0.2107\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2091, loss (valid): 0.2106\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2270, loss (valid): 0.2243\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2219, loss (valid): 0.2216\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2185, loss (valid): 0.2192\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2157, loss (valid): 0.2170\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2135, loss (valid): 0.2151\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2120, loss (valid): 0.2136\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2109, loss (valid): 0.2126\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2104, loss (valid): 0.2121\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2100, loss (valid): 0.2118\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2098, loss (valid): 0.2116\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2097, loss (valid): 0.2114\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2096, loss (valid): 0.2113\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2095, loss (valid): 0.2112\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2094, loss (valid): 0.2112\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2093, loss (valid): 0.2111\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2093, loss (valid): 0.2110\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2092, loss (valid): 0.2110\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2092, loss (valid): 0.2110\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2091, loss (valid): 0.2109\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2091, loss (valid): 0.2109\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2090, loss (valid): 0.2108\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2090, loss (valid): 0.2108\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2090, loss (valid): 0.2108\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2089, loss (valid): 0.2107\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2089, loss (valid): 0.2107\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2088, loss (valid): 0.2107\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2088, loss (valid): 0.2107\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2088, loss (valid): 0.2107\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2088, loss (valid): 0.2106\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2087, loss (valid): 0.2106\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2236, loss (valid): 0.2203\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2165, loss (valid): 0.2170\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2137, loss (valid): 0.2155\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2123, loss (valid): 0.2146\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2114, loss (valid): 0.2140\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2109, loss (valid): 0.2137\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2106, loss (valid): 0.2134\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2103, loss (valid): 0.2133\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2101, loss (valid): 0.2131\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2100, loss (valid): 0.2130\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2099, loss (valid): 0.2129\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2098, loss (valid): 0.2129\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2097, loss (valid): 0.2128\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2096, loss (valid): 0.2128\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2096, loss (valid): 0.2127\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2095, loss (valid): 0.2127\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2095, loss (valid): 0.2126\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2094, loss (valid): 0.2126\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2094, loss (valid): 0.2125\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2094, loss (valid): 0.2125\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2093, loss (valid): 0.2125\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2093, loss (valid): 0.2124\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2093, loss (valid): 0.2124\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2092, loss (valid): 0.2124\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2092, loss (valid): 0.2123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, iteration: 41236, loss (train): 0.2092, loss (valid): 0.2123\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2092, loss (valid): 0.2123\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2091, loss (valid): 0.2122\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2091, loss (valid): 0.2122\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2091, loss (valid): 0.2122\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2266, loss (valid): 0.2176\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2142, loss (valid): 0.2142\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2121, loss (valid): 0.2134\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2113, loss (valid): 0.2130\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2108, loss (valid): 0.2126\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2105, loss (valid): 0.2124\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2102, loss (valid): 0.2122\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2100, loss (valid): 0.2120\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2098, loss (valid): 0.2119\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2097, loss (valid): 0.2118\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2096, loss (valid): 0.2118\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2095, loss (valid): 0.2117\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2095, loss (valid): 0.2117\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2094, loss (valid): 0.2116\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2094, loss (valid): 0.2116\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2093, loss (valid): 0.2115\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2093, loss (valid): 0.2115\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2093, loss (valid): 0.2115\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2092, loss (valid): 0.2115\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2092, loss (valid): 0.2114\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2092, loss (valid): 0.2114\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2092, loss (valid): 0.2114\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2092, loss (valid): 0.2114\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2091, loss (valid): 0.2113\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2091, loss (valid): 0.2113\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2091, loss (valid): 0.2113\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2091, loss (valid): 0.2113\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2091, loss (valid): 0.2113\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2091, loss (valid): 0.2112\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2090, loss (valid): 0.2112\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2249, loss (valid): 0.2206\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2189, loss (valid): 0.2180\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2169, loss (valid): 0.2167\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2156, loss (valid): 0.2159\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2147, loss (valid): 0.2152\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2139, loss (valid): 0.2146\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2132, loss (valid): 0.2141\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2126, loss (valid): 0.2137\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2120, loss (valid): 0.2134\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2116, loss (valid): 0.2132\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2112, loss (valid): 0.2130\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2109, loss (valid): 0.2128\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2107, loss (valid): 0.2126\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2105, loss (valid): 0.2125\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2103, loss (valid): 0.2124\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2102, loss (valid): 0.2123\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2101, loss (valid): 0.2122\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2100, loss (valid): 0.2122\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2099, loss (valid): 0.2121\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2098, loss (valid): 0.2120\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2097, loss (valid): 0.2120\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2096, loss (valid): 0.2119\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2096, loss (valid): 0.2119\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2095, loss (valid): 0.2118\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2095, loss (valid): 0.2118\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2094, loss (valid): 0.2117\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2094, loss (valid): 0.2117\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2093, loss (valid): 0.2117\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2093, loss (valid): 0.2116\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2093, loss (valid): 0.2116\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2273, loss (valid): 0.2227\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2206, loss (valid): 0.2176\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2168, loss (valid): 0.2142\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2145, loss (valid): 0.2120\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2131, loss (valid): 0.2107\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2123, loss (valid): 0.2097\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2117, loss (valid): 0.2091\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2113, loss (valid): 0.2086\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2109, loss (valid): 0.2082\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2107, loss (valid): 0.2079\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2105, loss (valid): 0.2077\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2103, loss (valid): 0.2075\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2102, loss (valid): 0.2073\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2100, loss (valid): 0.2072\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2099, loss (valid): 0.2071\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2098, loss (valid): 0.2070\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2098, loss (valid): 0.2069\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2097, loss (valid): 0.2068\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2096, loss (valid): 0.2068\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2096, loss (valid): 0.2067\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2096, loss (valid): 0.2067\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2095, loss (valid): 0.2066\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2095, loss (valid): 0.2066\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2094, loss (valid): 0.2066\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2094, loss (valid): 0.2065\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2094, loss (valid): 0.2065\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2094, loss (valid): 0.2065\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2093, loss (valid): 0.2064\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2093, loss (valid): 0.2064\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2093, loss (valid): 0.2064\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2283, loss (valid): 0.2236\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2220, loss (valid): 0.2202\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2192, loss (valid): 0.2170\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2167, loss (valid): 0.2139\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2147, loss (valid): 0.2117\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2133, loss (valid): 0.2102\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2126, loss (valid): 0.2093\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2121, loss (valid): 0.2087\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2118, loss (valid): 0.2082\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2115, loss (valid): 0.2079\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2113, loss (valid): 0.2076\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2111, loss (valid): 0.2074\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2110, loss (valid): 0.2072\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2109, loss (valid): 0.2071\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2108, loss (valid): 0.2069\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2107, loss (valid): 0.2068\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2106, loss (valid): 0.2067\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2105, loss (valid): 0.2066\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2104, loss (valid): 0.2065\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2104, loss (valid): 0.2064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, iteration: 33306, loss (train): 0.2103, loss (valid): 0.2064\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2103, loss (valid): 0.2063\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2102, loss (valid): 0.2063\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2102, loss (valid): 0.2062\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2101, loss (valid): 0.2062\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2101, loss (valid): 0.2061\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2101, loss (valid): 0.2061\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2100, loss (valid): 0.2061\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2100, loss (valid): 0.2060\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2100, loss (valid): 0.2060\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2234, loss (valid): 0.2186\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2165, loss (valid): 0.2156\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2141, loss (valid): 0.2145\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2131, loss (valid): 0.2140\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2125, loss (valid): 0.2136\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2120, loss (valid): 0.2133\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2117, loss (valid): 0.2130\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2114, loss (valid): 0.2128\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2111, loss (valid): 0.2126\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2109, loss (valid): 0.2124\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2106, loss (valid): 0.2122\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2105, loss (valid): 0.2121\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2103, loss (valid): 0.2119\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2101, loss (valid): 0.2118\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2100, loss (valid): 0.2117\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2099, loss (valid): 0.2116\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2098, loss (valid): 0.2115\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2097, loss (valid): 0.2115\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2096, loss (valid): 0.2114\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2095, loss (valid): 0.2113\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2094, loss (valid): 0.2113\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2094, loss (valid): 0.2113\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2093, loss (valid): 0.2112\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2093, loss (valid): 0.2112\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2092, loss (valid): 0.2112\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2092, loss (valid): 0.2111\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2091, loss (valid): 0.2111\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2091, loss (valid): 0.2111\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2091, loss (valid): 0.2111\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2090, loss (valid): 0.2110\n",
      "epoch: 0, iteration: 1586, loss (train): 0.2245, loss (valid): 0.2197\n",
      "epoch: 1, iteration: 3172, loss (train): 0.2178, loss (valid): 0.2155\n",
      "epoch: 2, iteration: 4758, loss (train): 0.2145, loss (valid): 0.2130\n",
      "epoch: 3, iteration: 6344, loss (train): 0.2128, loss (valid): 0.2118\n",
      "epoch: 4, iteration: 7930, loss (train): 0.2120, loss (valid): 0.2111\n",
      "epoch: 5, iteration: 9516, loss (train): 0.2115, loss (valid): 0.2106\n",
      "epoch: 6, iteration: 11102, loss (train): 0.2112, loss (valid): 0.2103\n",
      "epoch: 7, iteration: 12688, loss (train): 0.2109, loss (valid): 0.2100\n",
      "epoch: 8, iteration: 14274, loss (train): 0.2106, loss (valid): 0.2098\n",
      "epoch: 9, iteration: 15860, loss (train): 0.2104, loss (valid): 0.2096\n",
      "epoch: 10, iteration: 17446, loss (train): 0.2102, loss (valid): 0.2095\n",
      "epoch: 11, iteration: 19032, loss (train): 0.2101, loss (valid): 0.2093\n",
      "epoch: 12, iteration: 20618, loss (train): 0.2099, loss (valid): 0.2092\n",
      "epoch: 13, iteration: 22204, loss (train): 0.2098, loss (valid): 0.2091\n",
      "epoch: 14, iteration: 23790, loss (train): 0.2097, loss (valid): 0.2090\n",
      "epoch: 15, iteration: 25376, loss (train): 0.2096, loss (valid): 0.2090\n",
      "epoch: 16, iteration: 26962, loss (train): 0.2096, loss (valid): 0.2089\n",
      "epoch: 17, iteration: 28548, loss (train): 0.2095, loss (valid): 0.2089\n",
      "epoch: 18, iteration: 30134, loss (train): 0.2094, loss (valid): 0.2088\n",
      "epoch: 19, iteration: 31720, loss (train): 0.2094, loss (valid): 0.2088\n",
      "epoch: 20, iteration: 33306, loss (train): 0.2093, loss (valid): 0.2087\n",
      "epoch: 21, iteration: 34892, loss (train): 0.2093, loss (valid): 0.2087\n",
      "epoch: 22, iteration: 36478, loss (train): 0.2092, loss (valid): 0.2087\n",
      "epoch: 23, iteration: 38064, loss (train): 0.2092, loss (valid): 0.2086\n",
      "epoch: 24, iteration: 39650, loss (train): 0.2092, loss (valid): 0.2086\n",
      "epoch: 25, iteration: 41236, loss (train): 0.2091, loss (valid): 0.2086\n",
      "epoch: 26, iteration: 42822, loss (train): 0.2091, loss (valid): 0.2086\n",
      "epoch: 27, iteration: 44408, loss (train): 0.2091, loss (valid): 0.2085\n",
      "epoch: 28, iteration: 45994, loss (train): 0.2091, loss (valid): 0.2085\n",
      "epoch: 29, iteration: 47580, loss (train): 0.2091, loss (valid): 0.2085\n"
     ]
    }
   ],
   "source": [
    "#print(np.random.permutation(range(len(x_train))))\n",
    "n_epoch = 30\n",
    "batchsize = 16\n",
    "# ログの保存用\n",
    "results_train_data = []\n",
    "results_valid_data = []\n",
    "\n",
    "\n",
    "for data_num in range(len(x_train)):\n",
    "    # ログの保存用\n",
    "    results_train = {\n",
    "        'loss': [],\n",
    "        'accuracy': []\n",
    "    }\n",
    "    results_valid = {\n",
    "        'loss': [],\n",
    "        'accuracy': []\n",
    "    }\n",
    "    iteration = 0\n",
    "    for epoch in range(n_epoch):\n",
    "        # 各バッチ毎の目的関数の出力と分類精度の保存用\n",
    "        loss_list = []\n",
    "        #accuracy_list = []\n",
    "\n",
    "        for i in range(0, len(x_train[data_num]), batchsize):\n",
    "            # バッチを準備\n",
    "            x_train_batch = x_train[data_num][i:i+batchsize,:]\n",
    "            y_train_batch = y_train[data_num][i:i+batchsize,:]\n",
    "\n",
    "            # 予測値を出力\n",
    "            y_train_batch_pred = net[data_num](x_train_batch)\n",
    "            # 目的関数を適用し、分類精度を計算\n",
    "            loss_train_batch = RPS(y_train_batch, y_train_batch_pred)\n",
    "            #print(loss_train_batch)\n",
    "            #accuracy_train_batch = F.accuracy(y_train_batch_pred, y_train_batch)\n",
    "\n",
    "            loss_list.append(loss_train_batch.array)\n",
    "            #accuracy_list.append(accuracy_train_batch.array)\n",
    "\n",
    "            # 勾配のリセットと勾配の計算\n",
    "            net[data_num].cleargrads()\n",
    "            loss_train_batch.backward()\n",
    "\n",
    "            # パラメータの更新\n",
    "            optimizer[data_num].update()\n",
    "\n",
    "            # カウントアップ\n",
    "            iteration += 1\n",
    "        # 訓練データに対する目的関数の出力と分類精度を集計\n",
    "        loss_train = np.mean(loss_list)\n",
    "        #accuracy_train = np.mean(accuracy_list)\n",
    "\n",
    "        # 1エポック終えたら、検証データで評価\n",
    "        # 検証データで予測値を出力\n",
    "        with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "            y_val_pred = net[data_num](x_val[data_num])\n",
    "\n",
    "        #print(y_val)\n",
    "        # 目的関数を適用し、分類精度を計算\n",
    "        loss_val = RPS(y_val_pred, y_val[data_num])\n",
    "        #accuracy_val = F.accuracy(y_val_pred, y_val[data_num])\n",
    "\n",
    "        # 結果の表示\n",
    "        print('epoch: {}, iteration: {}, loss (train): {:.4f}, loss (valid): {:.4f}'.format(\n",
    "            epoch, iteration, loss_train, loss_val.array))\n",
    "\n",
    "        # ログを保存\n",
    "        results_train['loss'] .append(loss_train)\n",
    "        #results_train['accuracy'] .append(accuracy_train)\n",
    "        results_valid['loss'].append(loss_val.array)\n",
    "        #results_valid['accuracy'].append(accuracy_val.array)\n",
    "        \n",
    "    results_train_data.append(results_train)\n",
    "    results_valid_data.append(results_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8ed77e1470>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "results_train_data_all = []\n",
    "results_valid_data_all = []\n",
    "results_train_data_all = np.zeros(epoch+1)\n",
    "results_valid_data_all = np.zeros(epoch+1)\n",
    "# 目的関数の出力 (loss)\n",
    "for i in range(split_num):   \n",
    "    results_train_data_all += results_train_data[i]['loss']\n",
    "    results_valid_data_all += results_valid_data[i]['loss']\n",
    "    #plt.plot(results_train_data[i]['loss'], label='train')  # label で凡例の設定\n",
    "    #plt.plot(results_valid_data[i]['loss'], label='valid')  # label で凡例の設定\n",
    "    #plt.legend()  # 凡例の表示\n",
    "    #plt.figure()\n",
    "\n",
    "plt.plot(results_train_data_all / 10, label='train')  # label で凡例の設定\n",
    "plt.plot(results_valid_data_all / 10, label='valid')  # label で凡例の設定\n",
    "plt.legend()  # 凡例の表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results_train_data[0]['loss'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
