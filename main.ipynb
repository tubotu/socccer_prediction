{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label     HHATT     HHDEF     HAATT     HADEF     AHATT     AHDEF  \\\n",
      "13680     D -0.013286  0.055444 -0.032403  0.112291 -0.013286  0.163329   \n",
      "2729      L  1.006109  0.230130  0.488624  0.489483  0.985480  0.083888   \n",
      "26413     D -0.034506  0.105019  0.012418  0.435008 -0.061290  0.057348   \n",
      "8975      D  4.744033 -1.088280  1.720375 -1.439166  0.698823  0.749711   \n",
      "13324     W  0.016564 -0.053097  0.040713  0.194267  0.026022  0.175712   \n",
      "\n",
      "          AAATT     AADEF  \n",
      "13680 -0.032403 -0.015245  \n",
      "2729   0.432996 -0.060702  \n",
      "26413  0.395053  0.766563  \n",
      "8975   0.396043  1.203952  \n",
      "13324  0.040616  0.915641  \n",
      "          HHATT     HHDEF     HAATT     HADEF     AHATT     AHDEF     AAATT  \\\n",
      "13680 -0.013286  0.055444 -0.032403  0.112291 -0.013286  0.163329 -0.032403   \n",
      "2729   1.006109  0.230130  0.488624  0.489483  0.985480  0.083888  0.432996   \n",
      "26413 -0.034506  0.105019  0.012418  0.435008 -0.061290  0.057348  0.395053   \n",
      "8975   4.744033 -1.088280  1.720375 -1.439166  0.698823  0.749711  0.396043   \n",
      "13324  0.016564 -0.053097  0.040713  0.194267  0.026022  0.175712  0.040616   \n",
      "\n",
      "          AADEF  \n",
      "13680 -0.015245  \n",
      "2729  -0.060702  \n",
      "26413  0.766563  \n",
      "8975   1.203952  \n",
      "13324  0.915641  \n",
      "     W\n",
      "0  0.0\n",
      "1  0.0\n",
      "2  0.0\n",
      "3  0.0\n",
      "4  1.0\n"
     ]
    }
   ],
   "source": [
    "#data input \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "path = 'trainrat_new.txt'\n",
    "\n",
    "\n",
    "data = pd.read_csv(path,sep=' ')\n",
    "print(data.head())\n",
    "\n",
    "x = DataFrame(data.drop([\"label\"], axis=1))\n",
    "\n",
    "print(x.head())\n",
    "\n",
    "y = pd.DataFrame()\n",
    "\n",
    "for row in data[\"label\"]:\n",
    "    tmp_se = pd.Series( [ row == \"W\"],index = [\"W\"])\n",
    "    y = y.append( tmp_se, ignore_index=True )\n",
    "\n",
    "print( y.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define X-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "modelArelu = Sequential()\n",
    "modelArelu.add(Dense(10, activation='relu'))\n",
    "modelArelu.add(Dense(10, activation='relu'))\n",
    "modelArelu.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelArelu.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     3 ... 28183 28184 28185] TEST: [    2     8    17 ... 28166 28173 28176]\n",
      "Epoch 1/10\n",
      "25367/25367 [==============================] - 1s 37us/step - loss: 0.6569 - acc: 0.6059\n",
      "Epoch 2/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6515 - acc: 0.6147\n",
      "Epoch 3/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6509 - acc: 0.6170\n",
      "Epoch 4/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6506 - acc: 0.6153\n",
      "Epoch 5/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6503 - acc: 0.6142\n",
      "Epoch 6/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6499 - acc: 0.6164\n",
      "Epoch 7/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6500 - acc: 0.6158\n",
      "Epoch 8/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6495 - acc: 0.6173\n",
      "Epoch 9/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6498 - acc: 0.6157\n",
      "Epoch 10/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6497 - acc: 0.6158\n",
      "[[0.4044243 ]\n",
      " [0.7105591 ]\n",
      " [0.840841  ]\n",
      " ...\n",
      " [0.43311858]\n",
      " [0.44360483]\n",
      " [0.5276969 ]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "TRAIN: [    0     1     2 ... 28183 28184 28185] TEST: [   13    21    54 ... 28165 28170 28171]\n",
      "Epoch 1/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6494 - acc: 0.6164\n",
      "Epoch 2/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6491 - acc: 0.6196\n",
      "Epoch 3/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6489 - acc: 0.6184\n",
      "Epoch 4/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6490 - acc: 0.6167\n",
      "Epoch 5/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6490 - acc: 0.6185\n",
      "Epoch 6/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6489 - acc: 0.6178\n",
      "Epoch 7/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6488 - acc: 0.6180\n",
      "Epoch 8/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6487 - acc: 0.6190\n",
      "Epoch 9/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6484 - acc: 0.6175\n",
      "Epoch 10/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6486 - acc: 0.6188\n",
      "[[0.41986367]\n",
      " [0.4078181 ]\n",
      " [0.4373505 ]\n",
      " ...\n",
      " [0.42033303]\n",
      " [0.574109  ]\n",
      " [0.3620147 ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "TRAIN: [    0     1     2 ... 28183 28184 28185] TEST: [    6    16    42 ... 28140 28144 28157]\n",
      "Epoch 1/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6484 - acc: 0.6188\n",
      "Epoch 2/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6485 - acc: 0.6181\n",
      "Epoch 3/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6483 - acc: 0.6187\n",
      "Epoch 4/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6484 - acc: 0.6197\n",
      "Epoch 5/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6180\n",
      "Epoch 6/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6188\n",
      "Epoch 7/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6482 - acc: 0.6186\n",
      "Epoch 8/10\n",
      "25367/25367 [==============================] - 1s 33us/step - loss: 0.6479 - acc: 0.6184\n",
      "Epoch 9/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6182\n",
      "Epoch 10/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6479 - acc: 0.6198\n",
      "[[0.37404063]\n",
      " [0.27226973]\n",
      " [0.57153124]\n",
      " ...\n",
      " [0.4636049 ]\n",
      " [0.36187223]\n",
      " [0.6104661 ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "TRAIN: [    1     2     3 ... 28183 28184 28185] TEST: [    0     4     5 ... 28146 28151 28152]\n",
      "Epoch 1/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6503 - acc: 0.6167\n",
      "Epoch 2/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6501 - acc: 0.6171\n",
      "Epoch 3/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6501 - acc: 0.6177\n",
      "Epoch 4/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6501 - acc: 0.6163\n",
      "Epoch 5/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6499 - acc: 0.6173\n",
      "Epoch 6/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6501 - acc: 0.6175\n",
      "Epoch 7/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6498 - acc: 0.6184\n",
      "Epoch 8/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6500 - acc: 0.6183\n",
      "Epoch 9/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6501 - acc: 0.6200\n",
      "Epoch 10/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6498 - acc: 0.6167\n",
      "[[0.43699506]\n",
      " [0.5025271 ]\n",
      " [0.31738937]\n",
      " ...\n",
      " [0.40311396]\n",
      " [0.29145947]\n",
      " [0.61036146]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "TRAIN: [    0     1     2 ... 28183 28184 28185] TEST: [    3    11    12 ... 28153 28167 28175]\n",
      "Epoch 1/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6479 - acc: 0.6201\n",
      "Epoch 2/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6478 - acc: 0.6210\n",
      "Epoch 3/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6478 - acc: 0.6192\n",
      "Epoch 4/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6479 - acc: 0.6209\n",
      "Epoch 5/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6478 - acc: 0.6199\n",
      "Epoch 6/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6479 - acc: 0.6196\n",
      "Epoch 7/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6477 - acc: 0.6210\n",
      "Epoch 8/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6477 - acc: 0.6206\n",
      "Epoch 9/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6476 - acc: 0.6195\n",
      "Epoch 10/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6475 - acc: 0.6207\n",
      "[[0.9731317 ]\n",
      " [0.2916953 ]\n",
      " [0.50070006]\n",
      " ...\n",
      " [0.4265527 ]\n",
      " [0.32462734]\n",
      " [0.45833972]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "TRAIN: [    0     1     2 ... 28182 28183 28184] TEST: [    7    19    24 ... 28163 28172 28185]\n",
      "Epoch 1/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6484 - acc: 0.6213\n",
      "Epoch 2/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6210\n",
      "Epoch 3/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6482 - acc: 0.6208\n",
      "Epoch 4/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6481 - acc: 0.6205\n",
      "Epoch 5/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6478 - acc: 0.6214\n",
      "Epoch 6/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6479 - acc: 0.6219\n",
      "Epoch 7/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6479 - acc: 0.6211\n",
      "Epoch 8/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6477 - acc: 0.6219\n",
      "Epoch 9/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6479 - acc: 0.6207\n",
      "Epoch 10/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6477 - acc: 0.6231\n",
      "[[0.53410596]\n",
      " [0.40245327]\n",
      " [0.42052284]\n",
      " ...\n",
      " [0.36582738]\n",
      " [0.38678405]\n",
      " [0.22569577]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "TRAIN: [    0     1     2 ... 28180 28182 28185] TEST: [    9    26    29 ... 28181 28183 28184]\n",
      "Epoch 1/10\n",
      "25367/25367 [==============================] - 1s 32us/step - loss: 0.6494 - acc: 0.6206\n",
      "Epoch 2/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6494 - acc: 0.6207\n",
      "Epoch 3/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6497 - acc: 0.6192\n",
      "Epoch 4/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6493 - acc: 0.6183\n",
      "Epoch 5/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6498 - acc: 0.6206\n",
      "Epoch 6/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6496 - acc: 0.6192\n",
      "Epoch 7/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6494 - acc: 0.6192\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6494 - acc: 0.6194\n",
      "Epoch 9/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6495 - acc: 0.6200\n",
      "Epoch 10/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6493 - acc: 0.6221\n",
      "[[0.56167597]\n",
      " [0.3963182 ]\n",
      " [0.6430398 ]\n",
      " ...\n",
      " [0.42368534]\n",
      " [0.44770187]\n",
      " [0.65939415]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "TRAIN: [    0     2     3 ... 28183 28184 28185] TEST: [    1    15    25 ... 28177 28178 28180]\n",
      "Epoch 1/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6488 - acc: 0.6210\n",
      "Epoch 2/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6488 - acc: 0.6207\n",
      "Epoch 3/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6489 - acc: 0.6222\n",
      "Epoch 4/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6488 - acc: 0.6211\n",
      "Epoch 5/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6485 - acc: 0.6223\n",
      "Epoch 6/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6488 - acc: 0.6210\n",
      "Epoch 7/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6487 - acc: 0.6221\n",
      "Epoch 8/10\n",
      "25367/25367 [==============================] - 1s 33us/step - loss: 0.6486 - acc: 0.6216\n",
      "Epoch 9/10\n",
      "25367/25367 [==============================] - 1s 30us/step - loss: 0.6484 - acc: 0.6207\n",
      "Epoch 10/10\n",
      "25367/25367 [==============================] - 1s 31us/step - loss: 0.6483 - acc: 0.6233\n",
      "[[0.42804784]\n",
      " [0.32197353]\n",
      " [0.37104788]\n",
      " ...\n",
      " [0.17095874]\n",
      " [0.27996573]\n",
      " [0.563619  ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "TRAIN: [    0     1     2 ... 28183 28184 28185] TEST: [   10    20    43 ... 28121 28158 28182]\n",
      "Epoch 1/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6500 - acc: 0.6199\n",
      "Epoch 2/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6501 - acc: 0.6206\n",
      "Epoch 3/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6501 - acc: 0.6196\n",
      "Epoch 4/10\n",
      "25369/25369 [==============================] - 1s 30us/step - loss: 0.6498 - acc: 0.6208\n",
      "Epoch 5/10\n",
      "25369/25369 [==============================] - 1s 30us/step - loss: 0.6500 - acc: 0.6195\n",
      "Epoch 6/10\n",
      "25369/25369 [==============================] - 1s 30us/step - loss: 0.6498 - acc: 0.6204\n",
      "Epoch 7/10\n",
      "25369/25369 [==============================] - 1s 30us/step - loss: 0.6498 - acc: 0.6219\n",
      "Epoch 8/10\n",
      "25369/25369 [==============================] - 1s 30us/step - loss: 0.6499 - acc: 0.6199\n",
      "Epoch 9/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6496 - acc: 0.6202\n",
      "Epoch 10/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6501 - acc: 0.6209\n",
      "[[0.33589718]\n",
      " [0.28653806]\n",
      " [0.5136746 ]\n",
      " ...\n",
      " [0.44097656]\n",
      " [0.30075407]\n",
      " [0.42764103]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "TRAIN: [    0     1     2 ... 28183 28184 28185] TEST: [   28    48    59 ... 28162 28168 28169]\n",
      "Epoch 1/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6487 - acc: 0.6204\n",
      "Epoch 2/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6487 - acc: 0.6210\n",
      "Epoch 3/10\n",
      "25369/25369 [==============================] - 1s 30us/step - loss: 0.6486 - acc: 0.6202\n",
      "Epoch 4/10\n",
      "25369/25369 [==============================] - 1s 30us/step - loss: 0.6484 - acc: 0.6217\n",
      "Epoch 5/10\n",
      "25369/25369 [==============================] - 1s 34us/step - loss: 0.6483 - acc: 0.6203\n",
      "Epoch 6/10\n",
      "25369/25369 [==============================] - 1s 37us/step - loss: 0.6486 - acc: 0.6211\n",
      "Epoch 7/10\n",
      "25369/25369 [==============================] - 1s 31us/step - loss: 0.6483 - acc: 0.6213\n",
      "Epoch 8/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6482 - acc: 0.6213\n",
      "Epoch 9/10\n",
      "25369/25369 [==============================] - 1s 30us/step - loss: 0.6484 - acc: 0.6187\n",
      "Epoch 10/10\n",
      "25369/25369 [==============================] - 1s 29us/step - loss: 0.6480 - acc: 0.6209\n",
      "[[0.56341594]\n",
      " [0.4691869 ]\n",
      " [0.58295834]\n",
      " ...\n",
      " [0.58190924]\n",
      " [0.32308304]\n",
      " [0.34749883]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "cvscores = []\n",
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "for train, test in kfold.split(x, y):\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train, X_test = x.iloc[train], x.iloc[test]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    # Fit the model\n",
    "    modelArelu.fit(X_train.values, y_train.values,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1\n",
    "                  )\n",
    "\n",
    "\n",
    "    results = modelArelu.predict(X_test, batch_size=batch_size, verbose=0, steps=None)\n",
    "    \n",
    "    print(results)\n",
    "    print(y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From /home/eggplant2/rintaro/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/eggplant2/rintaro/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/eggplant2/rintaro/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2462 - acc: 0.9239 - val_loss: 0.1191 - val_acc: 0.9622\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1045 - acc: 0.9680 - val_loss: 0.0946 - val_acc: 0.9731\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0758 - acc: 0.9772 - val_loss: 0.0811 - val_acc: 0.9764\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0610 - acc: 0.9816 - val_loss: 0.0842 - val_acc: 0.9769\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0517 - acc: 0.9851 - val_loss: 0.0952 - val_acc: 0.9759\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0438 - acc: 0.9865 - val_loss: 0.0853 - val_acc: 0.9783\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0399 - acc: 0.9884 - val_loss: 0.0781 - val_acc: 0.9808\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0354 - acc: 0.9897 - val_loss: 0.0913 - val_acc: 0.9804\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0341 - acc: 0.9901 - val_loss: 0.0804 - val_acc: 0.9816\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0297 - acc: 0.9912 - val_loss: 0.0896 - val_acc: 0.9825\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0264 - acc: 0.9924 - val_loss: 0.0898 - val_acc: 0.9827\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0258 - acc: 0.9928 - val_loss: 0.0885 - val_acc: 0.9818\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0228 - acc: 0.9937 - val_loss: 0.1013 - val_acc: 0.9823\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0221 - acc: 0.9937 - val_loss: 0.1040 - val_acc: 0.9818\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0232 - acc: 0.9939 - val_loss: 0.1135 - val_acc: 0.9823\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0215 - acc: 0.9940 - val_loss: 0.1107 - val_acc: 0.9818\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0197 - acc: 0.9946 - val_loss: 0.0987 - val_acc: 0.9833\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0179 - acc: 0.9952 - val_loss: 0.1132 - val_acc: 0.9829\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0181 - acc: 0.9952 - val_loss: 0.0999 - val_acc: 0.9837\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0201 - acc: 0.9949 - val_loss: 0.1079 - val_acc: 0.9832\n",
      "Test loss: 0.10788093121316324\n",
      "Test accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy\n",
    "\n",
    "fold_num = 10\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
