{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28186\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "split_num = 10\n",
    "\n",
    "\n",
    "# data input \n",
    "path = 'trainrat_new.txt'\n",
    "data = pd.read_csv(path,sep=' ')\n",
    "print(len(data))\n",
    "\n",
    "# Data extraction,Win\n",
    "win_data = data[data.label == \"W\"]\n",
    "win_data = win_data.assign(W=1,D=0,L=0) \n",
    "win_data = win_data.drop(\"label\",axis=1)\n",
    "win_data = win_data.sample(n=len(win_data))# random sort\n",
    "\n",
    "# Data extraction,Draw\n",
    "draw_data = data[data.label == \"D\"]\n",
    "draw_data = draw_data.assign(W=0,D=1,L=0)\n",
    "draw_data = draw_data.drop(\"label\",axis=1)\n",
    "draw_data = draw_data.sample(n=len(draw_data))# random sort\n",
    "\n",
    "# Data extraction,Lose\n",
    "lose_data = data[data.label == \"L\"]\n",
    "lose_data = lose_data.assign(W=0,D=0,L=1) \n",
    "lose_data = lose_data.drop(\"label\",axis=1)\n",
    "lose_data = lose_data.sample(n=len(lose_data))# random sort\n",
    "\n",
    "# Group data together,use for normal k-fold\n",
    "all_data = pd.concat([win_data, draw_data, lose_data])\n",
    "all_data = all_data.sample(n=len(all_data))# random sort\n",
    "#yAll = xAll[[\"W\",\"D\",\"L\"]]\n",
    "\n",
    "# Data drop\n",
    "#xWin = xWin.drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "#xDraw = xDraw.drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "#xLose = xLose.drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "#xAll = xAll.drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "\n",
    "# Data separate and making dataset\n",
    "win_data_separate = []\n",
    "draw_data_separate = []\n",
    "lose_data_separate = []\n",
    "all_data_separate = []\n",
    "wdl_separate = []\n",
    "for i in range(split_num):\n",
    "    win_data_separate.append(win_data[i::split_num])\n",
    "    draw_data_separate.append(draw_data[i::split_num])\n",
    "    lose_data_separate.append(lose_data[i::split_num])\n",
    "    all_data_separate.append(all_data[i::split_num])\n",
    "    # merge for stratified sampling\n",
    "    wdl_separate.append(pd.concat([win_data_separate[i],draw_data_separate[i],lose_data_separate[i]]))\n",
    "    # assign a number to make final input data\n",
    "    wdl_separate[i] = wdl_separate[i].assign(separate_num=i)\n",
    "    all_data_separate[i] = all_data_separate[i].assign(separate_num=i)\n",
    "\n",
    "# integrate everything once\n",
    "wdl_separate_merge = wdl_separate[0]\n",
    "all_data_separate_merge = all_data_separate[0]\n",
    "for i in range(1,split_num):\n",
    "    wdl_separate_merge = wdl_separate_merge.append(wdl_separate[i])\n",
    "    all_data_separate_merge = all_data_separate_merge.append(all_data_separate[i])\n",
    "\n",
    "#print(len(wdl_separate_merge))\n",
    "#print(len(all_data_separate_merge))\n",
    "    \n",
    "    \n",
    "# make final input data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "xAll_train = []\n",
    "yAll_train = []\n",
    "xAll_val = []\n",
    "yAll_val = []\n",
    "for i in range(split_num):\n",
    "    x_train.append(wdl_separate_merge[wdl_separate_merge['separate_num'] != i])\n",
    "    x_val.append(wdl_separate_merge[wdl_separate_merge['separate_num'] == i])\n",
    "    xAll_train.append(all_data_separate_merge[all_data_separate_merge['separate_num'] != i])\n",
    "    xAll_val.append(all_data_separate_merge[all_data_separate_merge['separate_num'] == i])\n",
    "for i in range(split_num):\n",
    "    # delete separate_num\n",
    "    x_train[i] = x_train[i].drop(['separate_num'],axis=1)\n",
    "    x_val[i] = x_val[i].drop(['separate_num'],axis=1)\n",
    "    xAll_train[i] = xAll_train[i].drop(['separate_num'],axis=1)\n",
    "    xAll_val[i] = xAll_val[i].drop(['separate_num'],axis=1)\n",
    "    # random sort\n",
    "    x_train[i] = x_train[i].sample(n=len(x_train[i]))\n",
    "    x_val[i] = x_val[i].sample(n=len(x_val[i]))\n",
    "    xAll_train[i] = xAll_train[i].sample(n=len(xAll_train[i]))\n",
    "    xAll_val[i] = xAll_val[i].sample(n=len(xAll_val[i]))\n",
    "    \n",
    "    # separate x and y\n",
    "    y_train.append(x_train[i][[\"W\",\"D\",\"L\"]])\n",
    "    y_val.append(x_val[i][[\"W\",\"D\",\"L\"]])\n",
    "    yAll_train.append(xAll_train[i][[\"W\",\"D\",\"L\"]])\n",
    "    yAll_val.append(xAll_val[i][[\"W\",\"D\",\"L\"]])\n",
    "    x_train[i] = x_train[i].drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "    x_val[i] = x_val[i].drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "    xAll_train[i] = xAll_train[i].drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "    xAll_val[i] = xAll_val[i].drop([\"W\",\"D\",\"L\"],axis=1)\n",
    "    \n",
    "    #translate pandas to numpy\n",
    "    x_train[i] = x_train[i].values.astype('float32') \n",
    "    x_val[i] = x_val[i].values.astype('float32') \n",
    "    y_train[i] = y_train[i].values\n",
    "    y_val[i] = y_val[i].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPS(y_true, y_pred):\n",
    "    output = 0.\n",
    "    data_num = len(y_true)\n",
    "    for i in range(data_num):\n",
    "        times = len(y_true[i]) - 1 \n",
    "        cumulative_sum = 0.\n",
    "        score = 0.\n",
    "        for time in range(times):\n",
    "            cumulative_sum += y_true[i,time] - y_pred[i,time]\n",
    "            score += cumulative_sum ** 2\n",
    "        score /= times\n",
    "        output += score\n",
    "    \n",
    "    output /= data_num\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 3171, loss (train): 0.2123, loss (valid): 0.2077\n",
      "epoch: 1, iteration: 6342, loss (train): 0.2112, loss (valid): 0.2076\n",
      "epoch: 2, iteration: 9513, loss (train): 0.2110, loss (valid): 0.2075\n",
      "epoch: 3, iteration: 12684, loss (train): 0.2110, loss (valid): 0.2070\n",
      "epoch: 4, iteration: 15855, loss (train): 0.2109, loss (valid): 0.2075\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-653f12f348e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0my_train_batch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0;31m# 目的関数を適用し、分類精度を計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                     \u001b[0mloss_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                     \u001b[0;31m#print(loss_train_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0;31m#accuracy_train_batch = F.accuracy(y_train_batch_pred, y_train_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-91c6afebfc8e>\u001b[0m in \u001b[0;36mRPS\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mcumulative_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcumulative_sum\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/chainer/functions/math/basic_math.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(*xs)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mAddConstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mrhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preprocess_rhs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36m_check_data_type_forward\u001b[0;34m(self, in_data)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlight_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/chainer/functions/math/basic_math.py\u001b[0m in \u001b[0;36mcheck_type_forward\u001b[0;34m(self, in_types)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/chainer/utils/type_check.py\u001b[0m in \u001b[0;36m_argname\u001b[0;34m(in_types, names)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;34m'{} argument(s)'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             'Invalid number of arguments')\n\u001b[0;32m--> 527\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0min_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0min_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "learning_rate_list = [0.01,0.001,0.0001,0.00001]\n",
    "batchsize_list = [8,16,32]\n",
    "\n",
    "# craete model\n",
    "# net としてインスタンス化\n",
    "n_input = 8\n",
    "n_hidden = 8\n",
    "n_output = 3\n",
    "\n",
    "n_epoch = 20\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "    for batchsize in batchsize_list:\n",
    "        # create 10 model for 10-fold-crossvalidation\n",
    "        optimizer = []\n",
    "        net = []\n",
    "\n",
    "        for i in range(split_num):\n",
    "            net.append(Sequential(\n",
    "                L.Linear(n_input, n_hidden), F.relu,\n",
    "                L.Linear(n_hidden, n_hidden), F.relu,\n",
    "                L.Linear(n_hidden, n_hidden), F.relu,\n",
    "                L.Linear(n_hidden, n_output), F.softmax)\n",
    "            )\n",
    "            optimizer.append(chainer.optimizers.Adam(alpha=learning_rate))\n",
    "            optimizer[i].setup(net[i])\n",
    "\n",
    "        # ログの保存用\n",
    "        results_train_data = []\n",
    "        results_valid_data = []\n",
    "\n",
    "\n",
    "        for data_num in range(len(x_train)):\n",
    "            # ログの保存用\n",
    "            results_train = {\n",
    "                'loss': [],\n",
    "                'accuracy': []\n",
    "            }\n",
    "            results_valid = {\n",
    "                'loss': [],\n",
    "                'accuracy': []\n",
    "            }\n",
    "            iteration = 0\n",
    "            for epoch in range(n_epoch):\n",
    "                # 各バッチ毎の目的関数の出力と分類精度の保存用\n",
    "                loss_list = []\n",
    "                #accuracy_list = []\n",
    "\n",
    "                for i in range(0, len(x_train[data_num]), batchsize):\n",
    "                    # バッチを準備\n",
    "                    x_train_batch = x_train[data_num][i:i+batchsize,:]\n",
    "                    y_train_batch = y_train[data_num][i:i+batchsize,:]\n",
    "\n",
    "                    # 予測値を出力\n",
    "                    y_train_batch_pred = net[data_num](x_train_batch)\n",
    "                    # 目的関数を適用し、分類精度を計算\n",
    "                    loss_train_batch = RPS(y_train_batch, y_train_batch_pred)\n",
    "                    #print(loss_train_batch)\n",
    "                    #accuracy_train_batch = F.accuracy(y_train_batch_pred, y_train_batch)\n",
    "\n",
    "                    loss_list.append(loss_train_batch.array)\n",
    "                    #accuracy_list.append(accuracy_train_batch.array)\n",
    "\n",
    "                    # 勾配のリセットと勾配の計算\n",
    "                    net[data_num].cleargrads()\n",
    "                    loss_train_batch.backward()\n",
    "\n",
    "                    # パラメータの更新\n",
    "                    optimizer[data_num].update()\n",
    "\n",
    "                    # カウントアップ\n",
    "                    iteration += 1\n",
    "                # 訓練データに対する目的関数の出力と分類精度を集計\n",
    "                loss_train = np.mean(loss_list)\n",
    "                #accuracy_train = np.mean(accuracy_list)\n",
    "\n",
    "                # 1エポック終えたら、検証データで評価\n",
    "                # 検証データで予測値を出力\n",
    "                with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "                    y_val_pred = net[data_num](x_val[data_num])\n",
    "\n",
    "                #print(y_val)\n",
    "                # 目的関数を適用し、分類精度を計算\n",
    "                loss_val = RPS(y_val_pred, y_val[data_num])\n",
    "                #accuracy_val = F.accuracy(y_val_pred, y_val[data_num])\n",
    "\n",
    "                # 結果の表示\n",
    "                print('epoch: {}, iteration: {}, loss (train): {:.4f}, loss (valid): {:.4f}'.format(\n",
    "                    epoch, iteration, loss_train, loss_val.array))\n",
    "\n",
    "                # ログを保存\n",
    "                results_train['loss'] .append(loss_train)\n",
    "                #results_train['accuracy'] .append(accuracy_train)\n",
    "                results_valid['loss'].append(loss_val.array)\n",
    "                #results_valid['accuracy'].append(accuracy_val.array)\n",
    "\n",
    "            results_train_data.append(results_train)\n",
    "            results_valid_data.append(results_valid)\n",
    "\n",
    "        results_train_data_all = []\n",
    "        results_valid_data_all = []\n",
    "        results_train_data_all = np.zeros(n_epoch)\n",
    "        results_valid_data_all = np.zeros(n_epoch)\n",
    "        # 目的関数の出力 (loss)\n",
    "        for i in range(split_num):   \n",
    "            results_train_data_all += results_train_data[i]['loss']\n",
    "            results_valid_data_all += results_valid_data[i]['loss']\n",
    "\n",
    "        print('learning_rate: {}, batch_size: {}'.format(learning_rate,batchsize))\n",
    "        plt.plot(results_train_data_all / split_num, label='train')  # label で凡例の設定\n",
    "        plt.plot(results_valid_data_all / split_num, label='valid')  # label で凡例の設定\n",
    "        plt.legend()  # 凡例の表示\n",
    "        plt.figure()\n",
    "\n",
    "        print('train: {}'.format(results_train_data_all / split_num))\n",
    "        print('valid: {}'.format(results_valid_data_all / split_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
